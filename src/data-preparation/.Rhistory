<<<<<<< HEAD
blm2020 <- read.csv('../../datasets/BLM2020_Dutch_elections16.csv', stringsAsFactors = FALSE, sep = ',', na.strings=c("", "NA"))
setwd("C:/Users/marjo/Downloads/dprep-project/src/data-preparation")
blm2020 <- read.csv('../../datasets/BLM2020_Dutch_elections16.csv', stringsAsFactors = FALSE, sep = ',', na.strings=c("", "NA"))
blm2020 <- read.csv('../../datasets/dataset1/BLM2020_Dutch_elections16.csv', stringsAsFactors = FALSE, sep = ',', na.strings=c("", "NA"))
blm2021 <- read.csv('../../datasets/dataset2/BLM2021_Dutch_elections15.csv', stringsAsFactors = FALSE, sep = ',', na.strings=c("", "NA"))
dir.create('../../gen/data-preparation/temp', recursive= TRUE)
=======
data2020$percentage = data2020$count / sum(data2020$count) * 100
data2020$ymax = cumsum(data2020$fraction)
data2020$ymin = c(0, head(data2020$ymax, n=-1))
#Rounding up
data2020 <- round_df(data2020, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(data2020$category, data2020$percentage, "%")
ggplot(data2020, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
#cleaning the data
BLM2020$datetime<-gsub("@\\S*", "", BLM2020$Text)
#cleaning the data
BLM2020$Text<-gsub("@\\S*", "", BLM2020$Text)
#cleaning the data
BLM2020$Text <- gsub("@\\S*", "", BLM2020$Text)
#cleaning the data
BLM2020$text <- gsub("@\\S*", "", BLM2020$text)
BLM2020$text <- gsub("amp", "", BLM2020$text)
BLM2020$text <- gsub("[\r\n]", "", BLM2020$text)
BLM2020$text <- gsub("[[:punct:]]", "", BLM2020$text)
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(Text) %>%
unnest_tokens(word, Text)
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(stop_words)
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of Bill Gates",
subtitle = "Stop words removed from the list")
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM",
subtitle = "Stop words removed from the list")
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(stop_words("de","je","het", "dat", "van", "en", "een", "als", "met", "voor"))
tweets <- BLM2020 %>%
na.omit() %>%
unnest_tokens(word, text)
sw<- tibble(stop_words("de"))
sw<- tibble(stopwords("de"))
library(rtweet)
library(dplyr)
library(tidyr)
library(tidytext)
library(ggplot.multistats)
library(ggplot2)
library(forestmangr)
library(syuzhet)
library(tidyverse)
library(readxl) # read excel
library(tibble) # tobble dataframe
library(dplyr) # piping
library(stringr) # character manipulation
library(tidytext)
library(tokenizers)
tweets <- BLM2020 %>%
na.omit() %>%
unnest_tokens(word, text)
#remove stop words
sw<- tibble(stopwords("de"))
tweets <- BLM2020 %>%
na.omit() %>%
unnest_tokens(word, text)
#remove stop words
sw<- tibble(stopwords("nl"))
?stopwords
?tibble
tweets <- BLM2020 %>%
na.omit() %>%
unnest_tokens(word, text)
#remove stop words
sw<- tibble(stopwords("de"))
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(stop_words)
`data_clean <- BLM2020 %>%
mutate(linenumber = row_number()) %>%
unnest_tokens(word, feedback) %>%
anti_join(get_stopwords(language = "nl") ) %>%
ungroup()`
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl"))
?get_stopwords
`data_clean <- BLM2020 %>%
mutate(linenumber = row_number()) %>%
unnest_tokens(word, feedback) %>%
anti_join(get_stopwords(language = 'dutch') ) %>%
ungroup()`
stopwordslangs
`data_clean <- BLM2020 %>%
mutate(linenumber = row_number()) %>%
unnest_tokens(word, feedback) %>%
anti_join(get_stopwords(stopwordslangs) ) %>%
ungroup()`
data_clean <- data %>%
mutate(linenumber = row_number()) %>%
unnest_tokens(word, feedback) %>%
anti_join(get_stopwords(language = "de") ) %>%
ungroup()`
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords)
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "en", source = "snowball"))
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(stop_words)
`data_clean <- BLM2020 %>%
mutate(linenumber = row_number()) %>%
unnest_tokens(word, feedback) %>%
anti_join(get_stopwords(language = "de") ) %>%
ungroup()`
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM",
subtitle = "Stop words removed from the list")
install.packages("stopwords")
library(stopwords)
#removing stop words from the text - so the most frequent words are not or at and
tweets <- BLM2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM",
subtitle = "Stop words removed from the list")
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM",
subtitle = "Stop words removed from the list")
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM",
subtitle = "Stop words removed from the list")
# Converting tweets to ASCII to trackle strange characters
tweets <- iconv(tweets, from="UTF-8", to="ASCII", sub="")
# removing retweets, in case needed
tweets <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets)
# removing mentions, in case needed
tweets <-gsub("@\\w+","",tweets)
ew_sentiment<-get_nrc_sentiment((tweets))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores")+
theme_minimal()
#create date class
BLM2020$Datetime <- as.Date(BLM2020$Datetime, format = "%d/%m/%y")
plot(BLM2020$Datetime,                                      # Draw plot without x-axis
data_new$values,
type = "l",
xaxt = "n")
library(tidyverse)
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = displ, y =hwy))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweets, y =hwy))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = BLM2020$retweets, y =hwy))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = BLM2020$retweet, y =hwy))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y =hwy))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = likes))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = like))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = location()))
install.packages("lobstr")
library(rtweet)
library(dplyr)
library(tidyr)
library(tidytext)
library(ggplot.multistats)
library(ggplot2)
library(forestmangr)
library(syuzhet)
library(tidyverse)
library(readxl) # read excel
library(tibble) # tobble dataframe
library(dplyr) # piping
library(stringr) # character manipulation
library(tidytext)
library(tokenizers)
library(stopwords)
library(tidyverse)
library(lobstr)
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = location()))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = location))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = date))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = datetime))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = location))
#ploting retweets by location
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = text))
#ploting retweets by location
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = location))
#-------------------------------------------------------------------------------
# Preclean data 2020
#-------------------------------------------------------------------------------\n")
# Make current directory the working directory
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load packages
library(data.table)
library(dplyr)
library(tidyr)
# install.packages(pandas)
# library(pandas)
blm2020 <- read.csv('../../datasets/Dataset1/BLM2020_Dataset.csv', stringsAsFactors = FALSE, sep = '\t', na.strings=c("", "NA"))
# Get a first look of the data
View(blm2020)
count(blm2020)
# See if there are missing values
is.na(blm2020)
sum(is.na(blm2020$Datetime))
sum(is.na(blm2020$Tweet.Id))
sum(is.na(blm2020$Location))
which(is.na(blm2020))
blm2020<- na.omit(blm2020)
# Remove duplicates with the distinct function
sum(duplicated(blm2020))
blm2020 %>% distinct(blm2020$Tweet.Id)
# See the type of data of the variables
glimpse(blm2020)
as.Date(blm2020$Datetime)
# Separate the date and the time into 2 variables
blm2020$Date <- sapply(strsplit(as.character(blm2020$Datetime), " "), "[", 1)
blm2020$Time <- sapply(strsplit(as.character(blm2020$Datetime), " "), "[", 2)
#see the class of the date
class(blm2020$Date)
# The data is a character and needs to be converted into a date variable
blm2020$Date <- as.Date(factor(blm2020$Date))
# Make the Time variable readable
blm2020$Time<- gsub(x=blm2020$Time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blm2020 = subset(blm2020, select = -c(Datetime))
# Remove attributes you don't need
# blm2020 = subset(blm2020, select = -c(X, Y))
# Filter on the location
# location <- c("NL", "nl", "Netherlands", "netherlands", "The Netherlands", "the netherlands", "Nederland", "nederland", "Holland", "holland", "Amsterdam", "010", "020", "Rotterdam", "Het mooie Brabant")
# blm2020_filtered <- blm2020 %>% filter(Location %in% location)
# View(blm2020_filtered)
# Try group_by
#If we need to filter on date
# bike_share_rides_past <- bike_share_rides %>%
#   filter(date <= today())
#Language detection, doesn't work for me
#install.packages("cld2")
#library("cld2")
#install.packages("cld3")
#detect_language(blm2020$Text)
#dir.create('../../gen/data-preparation/temp', recursive= TRUE)
write.table(blm2020_filtered, '../../gen/data-preparation/temp/tempfile1.csv')
#-------------------------------------------------------------------------------
# Preclean data 2021
#-------------------------------------------------------------------------------\n")
blm2021 <- read.csv('../../datasets/dataset2/BLM2021_Dataset.csv', stringsAsFactors = FALSE, sep = '\t', na.strings=c("", "NA"))
# Get a first look of the data
View(blm2021)
count(blm2021)
# See if there are missing values
is.na(blm2021)
sum(is.na(blm2021$Datetime))
sum(is.na(blm2021$Tweet.Id))
sum(is.na(blm2021$Location))
which(is.na(blm2021))
blm2021<- na.omit(blm2021)
# Remove duplicates with the distinct function
sum(duplicated(blm2021))
blm2021 %>% distinct(blm2021$Tweet.Id)
# See the type of data of the variables
glimpse(blm2021)
as.Date(blm2021$Datetime)
# Separate the date and the time into 2 variables
blm2021$Date <- sapply(strsplit(as.character(blm2021$Datetime), " "), "[", 1)
blm2021$Time <- sapply(strsplit(as.character(blm2021$Datetime), " "), "[", 2)
#see the class of the date
class(blm2021$Date)
# The data is a character and needs to be converted into a date variable
blm2021$Date <- as.Date(blm2021$Date)
# Make the Time variable readable
blm2021$Time<- gsub(x=blm2021$Time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blm2021 = subset(blm2021, select = -c(Datetime))
# Remove attributes you don't need
# blm2020 = subset(blm2020, select = -c(X, Y))
# Filter on the location
# location <- c("NL", "nl", "Netherlands", "netherlands", "The Netherlands", "the netherlands", "Nederland", "nederland", "Holland", "holland", "Amsterdam", "010", "020", "Rotterdam", "Het mooie Brabant")
# blm2020_filtered <- blm2020 %>% filter(Location %in% location)
# View(blm2020_filtered)
# Try group_by
#If we need to filter on date
# bike_share_rides_past <- bike_share_rides %>%
#   filter(date <= today())
#Language detection, doesn't work for me
#install.packages("cld2")
#library("cld2")
#install.packages("cld3")
#detect_language(blm2020$Text)
dir.create('../../gen/data-preparation/temp', recursive= TRUE)
write.table(blm2020_filtered, '../../gen/data-preparation/temp/tempfile2.csv')
blm2020 <- read.csv('../../datasets/Dataset1/BLM2020_Dataset.csv', stringsAsFactors = FALSE, sep = '\t', na.strings=c("", "NA"))
blm2020<- na.omit(blm2020)
blm2020 %>% distinct(blm2020$Tweet.Id)
# See the type of data of the variables
glimpse(blm2020)
as.Date(blm2020$Datetime)
# Separate the date and the time into 2 variables
blm2020$Date <- sapply(strsplit(as.character(blm2020$Datetime), " "), "[", 1)
blm2020$Time <- sapply(strsplit(as.character(blm2020$Datetime), " "), "[", 2)
#see the class of the date
class(blm2020$Date)
# The data is a character and needs to be converted into a date variable
blm2020$Date <- as.Date(factor(blm2020$Date))
# Make the Time variable readable
blm2020$Time<- gsub(x=blm2020$Time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blm2020 = subset(blm2020, select = -c(Datetime))
as.Date(blm2020$datetime)
# Separate the date and the time into 2 variables
blm2020$date <- sapply(strsplit(as.character(blm2020$Datetime), " "), "[", 1)
blm2020$time <- sapply(strsplit(as.character(blm2020$Datetime), " "), "[", 2)
#see the class of the date
class(blm2020$Date)
# The data is a character and needs to be converted into a date variable
blm2020$date <- as.Date(factor(blm2020$Date))
# Make the Time variable readable
blm2020$time<- gsub(x=blm2020$Time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blm2020 = subset(blm2020, select = -c(Datetime))
blm2021 <- read.csv('../../datasets/dataset2/BLM2021_Dataset.csv', stringsAsFactors = FALSE, sep = '\t', na.strings=c("", "NA"))
# See if there are missing values
is.na(blm2021)
blm2021<- na.omit(blm2021)
# Remove duplicates with the distinct function
sum(duplicated(blm2021))
blm2021 %>% distinct(blm2021$Tweet.Id)
# See the type of data of the variables
glimpse(blm2021)
as.Date(blm2021$Datetime)
as.Date(blm2021$datetime)
# Separate the date and the time into 2 variables
blm2021$date <- sapply(strsplit(as.character(blm2021$Datetime), " "), "[", 1)
blm2021$time <- sapply(strsplit(as.character(blm2021$Datetime), " "), "[", 2)
#see the class of the date
class(blm2021$date)
# The data is a character and needs to be converted into a date variable
blm2021$Date <- as.Date(blm2021$date)
# Make the Time variable readable
blm2021$Time<- gsub(x=blm2021$time, pattern="+00:00",replacement="",fixed=T)
View(blm2020)
#ploting retweets by datetime
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = datetime))
ggplot(data = <BLM2020>) +
ggplot(data = BLM2020) +
<GEOM_FUNCTION>(mapping = aes(text)
ggplot(data = BLM2020) +
GEOM_FUNCTION>(mapping = aes(text)
#ploting retweets by datetime
#need to separate date from time
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = datetime, color = class))
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, size = class))
ggplot(data = BLM 2020) +
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = datetime, y = retweet, size = class))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = datetime, y = retweet)
#ploting retweets by datetime
#need to separate date from time
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = datetime, y = retweet))
#ploting retweets by datetime
#need to separate date from time
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = datetime))
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = datetime, y = retweet, color = "blue")
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = datetime, y = retweet, color = "blue")
#ploting retweets by datetime
#need to separate date from time
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = retweet, y = datetime), color = "blue")
View(BLM2020)
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = user_amount_followers, y = user_amount_friends), color = "blue")
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = user_amount_status), color = "blue")
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = user_amount_status, y = user), color = "blue")
ggplot(data = BLM2020) +
geom_point(mapping = aes(x = user_amount_status, y = location), color = "blue")
state.name[grep("VVD", state.name)]
state.name[grep = c(("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD"), state.name)]
state.name[grep = c("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD"), state.name)]
state.name[grep = c("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD"), state.name)]
state.name[grep c("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD"), state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD"), state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", "SGP", "50PLUS", "DENK", "OSF" state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", "SGP", "50PLUS", "DENK", "OSF" state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", "SGP", state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", "SGP" state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD"), state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", state.name)]
>>>>>>> 8a9b1baa6daf5453cc64f7c976eb202588348505
