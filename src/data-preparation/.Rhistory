xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
#Adding columns
RLRdata2021$fraction = RLRdata2021$count / sum(RLRdata2021$count)
RLRdata2021$percentage = RLRdata2021$count / sum(RLRdata2021$count) * 100
RLRdata2021$ymax = cumsum(RLRdata2021$fraction)
RLRdata2021$ymin = c(0, head(RLRdata2021$ymax, n=-1))
#Rounding up
RLRdata2021 <- round_df(RLRdata2021, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(RLRdata2021$category, RLRdata2021$percentage, "%")
ggplot(RLRdata2021, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
blm_merged$text <-  gsub("https\\S*", "", blm_merged$text)
blm_merged$text <-  gsub("@\\S*", "", blm_merged$text)
blm_merged$text  <-  gsub("amp", "", blm_merged$text)
blm_merged$text  <-  gsub("[\r\n]", "", blm_merged$text)
blm_merged$text  <-  gsub("[[:punct:]]", "", blm_merged$text)
tweets <- function(year){
tweets2020 <- blm_merged[blm_merged$year == year,] %>%
select(text) %>%
unnest_tokens(word, text)
tweets2020 <- tweets2020 %>%
anti_join(stop_words)
}
tweets(2020)
tweets(2021)
#making a histogram
histogram_words <- function(year){
tweets(year) %>%
dplyr::count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in blm dataset",
subtitle = "Stop words removed from the list")
}
histogram_words(2020)
histogram_words(2021)
sentiment <- function(year){
tweets_sentiment <- iconv(tweets(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
sentiment(2021)
retweet_location <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = like, y = date))
}
retweet_location(2020)
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'], sep = '\t', na.string = c(" ", "NA"))
write.csv(blm_data, paste0('../../datasets/', i['target']), quote = TRUE, fileEncoding = "UTF-8")
}
#-------------------------------------------------------------------------------
# Preclean data 2020
#-------------------------------------------------------------------------------
# Make current directory the working directory
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load packages
library(data.table)
library(dplyr)
library(tidyr)
library(textclean)
# Download the data
filenames = c('../../datasets/BLM2020_dataset.csv',
'../../datasets/BLM2021_dataset.csv')
data_blm = lapply(filenames,
function(fn) {
read.csv(
fn, sep = ',' , na.string = c(" ", "NA"),
encoding = 'UTF-8'
)
})
# Loop through all of the data
dir.create('../../gen/data-preparation/temp', recursive= TRUE)
prepared_data <- list()
for (i in seq(along=data_blm)) {
print(i)
blmdata = data_blm[[i]]
fn = filenames[i]
extracted_filename = rev(strsplit(fn, '/')[[1]])[1]
# Set the NA's right
blmdata$retweeted_tweet[is.na(blmdata$retweeted_tweet)] <- 0
blmdata$quoted_tweet[is.na(blmdata$quoted_tweet)] <- "No"
blmdata$location <- replace(blmdata$location, blmdata$location == "", NA)
blmdata$user_description <- replace(blmdata$user_description, blmdata$user_description == "", NA)
blmdata$quoted_tweet <- replace(blmdata$quoted_tweet, blmdata$quoted_tweet == "", NA)
# Remove duplicates with the distinct function
blmdata %>% distinct(blmdata$tweet_id)
## locale-specific version of the date
format(Sys.Date(), "%a %b %d")
# The data is a character and needs to be converted into a date variable
blmdata$tweet_date <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 1)
blmdata$tweet_time <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 2)
blmdata$tweet_date <- as.Date.character(blmdata$tweet_date, format = c("%Y-%m-%d"))
blmdata$tweet_time <- gsub(blmdata$tweet_time, pattern="+00:00",replacement="",fixed=T)
# The data is a character and needs to be converted into a date variable
blmdata$user_created_date <- sapply(strsplit(as.character(blmdata$user_created), " "), "[", 1)
blmdata$user_created_time <- sapply(strsplit(as.character(blmdata$user_created), " "), "[", 2)
blmdata$user_created_date <- as.Date.character(blmdata$user_created_date, format = c("%Y-%m-%d"))
blmdata$user_created_time <- gsub(x=blmdata$user_created_time, pattern="+00:00",replacement="",fixed=T)
# remove extra variables
blmdata <- subset(blmdata, select = -datetime)
blmdata <- subset(blmdata, select = -user_created)
blmdata <- subset(blmdata, select = -X)
# Make sure that the other variables are measured correctly
blmdata$retweeted_tweet <- as.integer(blmdata$retweeted_tweet)
# remove weird characters (rendered) content tweet and user description
blmdata$text <- gsub(blmdata$text, pattern = "\r\n",replacement= "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "©", replacement= "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "¦", replacement= "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "Ã", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "f", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "ð", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "Y", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "~", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "¯", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "ª", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "¸", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "&gt;", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "â", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "¤;", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "ï", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "T", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "«", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "¨", replacement = "", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "'ª", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "¢", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "o;", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "®", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "â", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "Y", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "~", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "o", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "½", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "T", replacement = "&", fixed = T)
blmdata$text <- gsub(blmdata$text, pattern = "^", replacement = "&", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "\r\n", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "©", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "¦", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "Ã", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "f", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "ð", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "Y", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "~", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "¯", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "ª", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "¸", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "&gt;", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "â", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "¤", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "ï", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "T", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "«", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "¨", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "&amp;", replacement = "&", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "¢", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "'ª", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "o", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "®", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "â", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "Y", replacement = "&", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "~", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "o", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "½", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "T", replacement = "", fixed = T)
blmdata$rendered_content <- gsub(blmdata$rendered_content, pattern = "^", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "\r\n", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "©", replacement= "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "¦", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "Ã", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "f", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "ð", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "Y", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "~", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "¯", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "ª", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "¸", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "&gt;", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "â", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "¤", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "ï", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "T", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "«", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "¨", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "&amp;", replacement = "&", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "'ª", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "o", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "®", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "â", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "Y", replacement = "&", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "~", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "o", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "½", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "T", replacement = "", fixed = T)
blmdata$user_description <- gsub(blmdata$user_description, pattern = "^", replacement = "", fixed = T)
#replace data that is retreived the wrong way
replace_contraction(blmdata$rendered_content)
replace_emoticon(blmdata$redered_content)
replace_incomplete(blmdata, ".")
# Transform the tweet_id and user_id into fully written numbers
blmdata$tweet_id_full <- format(blmdata$tweet_id, scientific = FALSE)
blmdata$user_id_full <- format(blmdata$tweet_id, scientific = FALSE)
# clean source attribute to useful
html_tags <- c(
"<bold>Random</bold> text with symbols: &nbsp; &lt; &gt; &amp; &quot; &apos;",
"<p>More text</p> &cent; &pound; &yen; &euro; &copy; &reg;"
)
blmdata$source_tweet<- replace_html(blmdata$source_tweet)
prepared_data[[i]] <- blmdata
write.table(blmdata, paste0('../../gen/data-preparation/temp/', extracted_filename))
}
rm(blmdata)
# load cleaned data
library(plyr)
library(dplyr)
blm2020<-read.csv('../../gen/data-preparation/temp/BLM2020_dataset.csv', sep = '', na.strings=c("", "NA"), row.names=NULL)
blm2021<-read.csv('../../gen/data-preparation/temp/BLM2021_dataset.csv', sep = '', na.strings=c("", "NA"), row.names=NULL)
# merge data
blm_merged <- rbind(blm2020, blm2021)
blm_merged$quote_count <- as.integer(blm_merged$quote_count)
##  ----------------------cleaning merged data; remove first column, set date as.Date and add column with year --------------------------- ##
# remove first column
blm_merged <- subset(blm_merged, select = -row.names)
# Set date into as.Date since we csv does not recognize as.Date
blm_merged$tweet_date <- as.Date(blm_merged$tweet_date)
blm_merged$user_created_date <- as.Date(blm_merged$user_created_date)
# add column with year of tweets
blm_merged$year <- format(blm_merged$tweet_date, format = "%Y")
## --------------- end cleaning: write over in csv file -------------------##
write.csv(blm_merged, '../../gen/data-preparation/merging.csv')
View(blm_merged)
View(blm_merged)
# remove first column
# blm_merged <- subset(blm_merged, select = -X)
# blm_merged <- subset(blm_merged, select = -row.names)
# set user_created_date as date
blm_merged$user_created_date <- as.Date(blm_merged$user_created_date, format = c("%Y-%m-%d"))
# Set date into as.Date
blm_merged$tweet_date <- as.Date(blm_merged$tweet_date)
#Retweet
RLR <- function(year){
for (i in year){
retweet <- (sum(blm_merged[blm_merged$year == year,]$retweet, na.rm = T))
like <- (sum(blm_merged[blm_merged$year == year,]$like, na.rm = T))
reply <- (sum(blm_merged[blm_merged$year == year,]$reply, na.rm = T))
quoted <- (sum(blm_merged[blm_merged$year == year,]$quote_count, na.rm = T))
}
RLRdata <- data.frame(category=c("Retweet", "Like", "Reply", "Quoted"), count = c(retweet, like, reply, quoted))
return(RLRdata)
}
RLRdata2020 <- RLR(2020)
RLRdata2021 <- RLR(2021)
#Adding columns
RLRdata2020$fraction = RLRdata2020$count / sum(RLRdata2020$count)
RLRdata2020$percentage = RLRdata2020$count / sum(RLRdata2020$count) * 100
RLRdata2020$ymax = cumsum(RLRdata2020$fraction)
RLRdata2020$ymin = c(0, head(RLRdata2020$ymax, n=-1))
#Rounding up
RLRdata2020 <- round_df(RLRdata2020, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(RLRdata2020$category, RLRdata2020$percentage, "%")
ggplot(RLRdata2020, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
#Adding columns
RLRdata2021$fraction = RLRdata2021$count / sum(RLRdata2021$count)
RLRdata2021$percentage = RLRdata2021$count / sum(RLRdata2021$count) * 100
RLRdata2021$ymax = cumsum(RLRdata2021$fraction)
RLRdata2021$ymin = c(0, head(RLRdata2021$ymax, n=-1))
#Rounding up
RLRdata2021 <- round_df(RLRdata2021, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(RLRdata2021$category, RLRdata2021$percentage, "%")
ggplot(RLRdata2021, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
blm_merged$text <-  gsub("https\\S*", "", blm_merged$text)
blm_merged$text <-  gsub("@\\S*", "", blm_merged$text)
blm_merged$text  <-  gsub("amp", "", blm_merged$text)
blm_merged$text  <-  gsub("[\r\n]", "", blm_merged$text)
blm_merged$text  <-  gsub("[[:punct:]]", "", blm_merged$text)
tweets <- function(year){
tweets2020 <- blm_merged[blm_merged$year == year,] %>%
select(text) %>%
unnest_tokens(word, text)
tweets2020 <- tweets2020 %>%
anti_join(stop_words)
}
tweets(2020)
tweets(2021)
#making a histogram
histogram_words <- function(year){
tweets(year) %>%
dplyr::count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in blm dataset",
subtitle = "Stop words removed from the list")
}
histogram_words(2020)
histogram_words(2021)
sentiment <- function(year){
tweets_sentiment <- iconv(tweets(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
sentiment(2021)
retweet_location <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = like, y = date))
}
retweet_location(2020)
retweet_date <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = retweet, y = date), color = "blue")
}
retweet_date(2020)
retweet_date <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = retweet, y = tweet_date), color = "blue")
}
retweet_date(2020)
retweet_date(2021)
retweet_location <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = like, y = tweet_date))
}
retweet_location(2020)
retweet_location(2021)
followers_friends <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = user_amount_followers, y = user_amount_friends), color = "blue")
}
followers_friends(2020)
followers_friends(2021)
time_source_tweet <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = user_amount_followers, y = source_tweet), color = "blue")
}
time_source_tweet(2020)
time_source_tweet(2021)
names <- c("pvv|vvd|CDA|D66|GroenLinks|SP|PVDA|ChristenUnie|pvdd|50plus|DENK|FVD|BIJ1")
parties <- function(year){
length(grep(names, blm_merged[blm_merged$year == 2020,]$text))
}
parties(2020)
blm2020<-read.csv('../../gen/data-preparation/temp/BLM2020_dataset.csv', sep = ' ', na.strings=c("", "NA"))
blm2021<-read.csv('../../gen/data-preparation/temp/BLM2021_dataset.csv', sep = '', na.strings=c("", "NA"))
#removing stop words from the text - so the most frequent words are not or at and
tweets <- blm2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
#2020
# Converting tweets to ASCII to trackle strange characters
tweets_sentiment <- iconv(tweets, from="UTF-8", to="ASCII", sub="")
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
#2021
# Converting tweets to ASCII to trackle strange characters
tweets_sentiment_1 <- iconv(tweets, from="UTF-8", to="ASCII", sub="")
# removing retweets, in case needed
tweets_sentiment_1 <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment_1)
#remove dollar signs #better to do this in cleaning?
blm2020 <- gsub("\\$","", blm2020)
blm2021 <- gsub("\\$","", blm2021)
# create a list of tokens
#https://www.kaggle.com/rtatman/tokenization-tutorial
tokens_2020<-data.frame(text= blm2020) %>% unnest_tokens(word, text)
tokens_2020
tokens_2021<-data.frame(text=blm2021) %>% unnest_tokens(word, text)
tokens_2021
# create a list of tokens
#https://www.kaggle.com/rtatman/tokenization-tutorial
tokens_2020<-data.frame(text= blm2020) %>% unnest_tokens(word, text)
tokens_2020
tokens_2021<-data.frame(text=blm2021) %>% unnest_tokens(word, text)
tokens_2021
# get the sentiment from the first text:
tokens_2020 %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
dplyr::count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
#do the same for 2021
tokens_2021 %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
dplyr::count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
blm2020<-read.csv('../../gen/data-preparation/temp/BLM2020_dataset.csv', sep = ' ', na.strings=c("", "NA"))
blm2021<-read.csv('../../gen/data-preparation/temp/BLM2021_dataset.csv', sep = '', na.strings=c("", "NA"))
blm2020$sentiment<-get_sentiment(blm2020$text)
blm2021$sentiment<-get_sentiment(blm2021$text)
blm_merged$sentiment<-get_sentiment(blm_merged$text)
#2020
one.way_2020 <- aov(sentiment ~ source_tweet , data = blm2020)
summary(one.way_2020)
#2021
one.way_2021 <- aov(sentiment ~ source_tweet, data = blm2021)
summary(one.way_2021)
# See whether there are more likes to a tweet when a user has more followers
ANOVAlikes <- aov(like ~ user_amount_followers, data = blm_merged)
summary(ANOVAlikes)
# See whether there are more retweets to a tweet when a user has more followers
ANOVAretweets <- aov(retweet ~ user_amount_followers, data = blm_merged)
summary(ANOVAretweets)
# See whether sentiments cores differ with the year they are tweeted in
ANOVAyear <- aov(sentiment ~ year, data = blm_merged)
summary(ANOVAyear)
# See whether likes and retweets have an impact on followers of the user
#ANOVAfollowers <- aov(user_amount_followers ~ like*retweet, data = blm_merged)
#summary(ANOVAfollowers)
#counting the positive/negative tweets for 2020, 2021 and the merged file
#2020
blm2020$negative<-as.numeric(blm2020$sentiment <=1)
blm2020$positive<-as.numeric(blm2020$sentiment >1)
#2021
blm2021$negative<-as.numeric(blm2021$sentiment <=1)
blm2021$positive<-as.numeric(blm2021$sentiment >1)
#blm_merged
blm_merged$negative<-as.numeric(blm_merged$sentiment <=1)
blm_merged$positive<-as.numeric(blm_merged$sentiment >1)
#See whether the negative comments are dependent on the year
ANOVAsentiment_negative <- aov(negative ~ year, data = blm_merged)
summary(ANOVAsentiment_negative)
#The same for positive
ANOVAsentiment_positive <- aov(positive ~ year, data = blm_merged)
summary(ANOVAsentiment_positive)
#2020
ANOVAsentiment_negative_2020 <- aov(negative ~ date, data = blm2020)
#2020
ANOVAsentiment_negative_2020 <- aov(negative ~ tweet_date, data = blm2020)
summary(ANOVAsentiment_negative_2020)
ANOVAsentiment_positive_2020 <- aov(positive ~ tweet_date, data = blm2020)
summary(ANOVAsentiment_positive_2020)
#2021
ANOVAsentiment_positve_2021 <- aov(positive ~ date, data = blm2021)
#2021
ANOVAsentiment_positve_2021 <- aov(positive ~ tweet_date, data = blm2021)
summary(ANOVAsentiment_positve_2021)
ANOVAsentiment_negative_2021 <- aov(negative ~ tweet_date, data = blm2021)
summary(ANOVAsentiment_negative_2021)
