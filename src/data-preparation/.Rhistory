library(plotly)
library(shiny)
# install.packages("plotly")
# library(plotly)
library(DT)
# mobility <- read.csv("mobility_data.csv", sep = ';')
mobility$Date <- as.Date(mobility$date)
mobility$Province <- as.factor(mobility$sub_region_1)
ui <- fluidPage(
sidebarLayout(
sidebarPanel(
h2("COVID-19 Mobility Data"),
selectInput(inputId = "dv", label = "Category",
choices = c("Retail_Recreation", "Grocery_Pharmarcy", "Parks", "Transit_Stations", "Workplaces", "Residential"),
selected = "Grocery_Pharmarcy"),
selectInput(inputId = "provinces", "Province(s)",
choices = levels(mobility$Province),
multiple = TRUE,
selected = c("Utrecht", "Friesland", "Zeeland")),
dateRangeInput(inputId = "date", "Date range",
start = min(mobility$Date),
end   = max(mobility$Date)),
downloadButton(outputId = "download_data", label = "Download"),
),
mainPanel(
plotlyOutput(outputId = "plot"), br(),
em("Postive and negative percentages indicate an increase and decrease from the baseline period (median value between January 3 and February 6, 2020) respectively."),
br(), br(), br(),
DT::dataTableOutput(outputId = "table")
)
)
)
library(shiny)
install.packages("plotly")
library(plotly)
library(shiny)
install.packages("plotly")
library(plotly)
?rbind
BLM2020_filterd <- read.csv('../../gen/data-preparation/temp/tempfile1.csv', sep = '\t', na.strings=c("", "NA"))
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'],  sep = '\t', na.strings = c("", "NA"))
write.table(blm_data, paste0('../../datasets/', i['target']))
}
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'],  sep = '\t', na.strings = c("", "NA"))
write.table(blm_data, paste0('../../datasets/', i['target']))
}
blm_data <- fread(i['url'])
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- fread(i['url'])
write.table(blm_data, paste0('../../datasets/', i['target']))
}
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'], sep = '\t', na.string = c(" ", "NA"))
dir.create('../../datasets', recursive= TRUE)
write.csv(blm_data, paste0('../../datasets/', i['target']), quote = TRUE, fileEncoding = "")
}
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'], sep = '\t', na.string = c(" ", "NA"))
dir.create('../../datasets', recursive= TRUE)
write.csv(blm_data, paste0('../../datasets/', i['target']), quote = TRUE, fileEncoding = "")
}
dir.create('../../datasets', recursive= TRUE)
dir.create('../../datasets', recursive= TRUE)
dir.create('../../datasets', recursive= TRUE)
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'], sep = '\t', na.string = c(" ", "NA"))
dir.create('../../datasets', recursive= TRUE)
write.csv(blm_data, paste0('../../datasets/', i['target']), quote = TRUE, fileEncoding = "")
}
docs <- Corpus(VectorSource(text))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library(rtweet)
library(tidyr)
library(ggplot.multistats)
library(ggplot2)
library(forestmangr)
library(syuzhet)
library(tidyverse)
library(readxl) # read excel
library(tibble) # tobble dataframe
library(stringr) # character manipulation
library(tidytext)
library(tokenizers)
library(stopwords)
library(lobstr)
library(glue)
library(dplyr) # piping
setwd("~/Tilburg universiteit/Tweets_on_BlackLivesMatter_BLM/src/data-preparation")
blm_merged<-read.csv('../../gen/data-preparation/merging.csv', sep = ',', na.strings=c("", "NA"))
# remove first column
blm_merged <- subset(blm_merged, select = -X)
# set user_created_date as date
blm_merged$user_created_date <- as.Date(blm_merged$user_created_date, format = c("%Y-%m-%d"))
# Set date into as.Date
blm_merged$tweet_date <- as.Date(blm_merged$tweet_date)
docs <- Corpus(VectorSource(text))
docs <- Corpus(VectorSource(blm_merged$text))
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("nl"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
docs <- Corpus(VectorSource(blm_merged$text))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("dutch"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
clouds <- function(year){
docs <- Corpus(VectorSource(blm_merged[blm_merged$year == year,]$text))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("dutch"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
}
clouds(2020)
clouds(2021)
clouds(2020)
clouds(2021)
clouds(2020)
clouds(2021)
blm_merged$user_amount_followers <- as.integer(blm_merged$user_amount_followers, na.strings = "NA")
blm_merged$user_amount_friends <- as.integer(blm_merged$user_amount_friends, na.strings = "NA")
blm_merged$user_amount_status <- as.integer(blm_merged$user_amount_status, na.strings = "NA")
blm_merged$user_listed_count <- as.integer(blm_merged$user_listed_count, na.strings = "NA")
blm_merged$user_media_count <- as.integer(blm_merged$user_media_count, na.strings = "NA")
followers_friends <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = user_amount_followers,
y = user_amount_friends, color = "blue"))
}
followers_friends(2020)
followers_friends(2021)
time_source_tweet <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = user_amount_followers, y = source_tweet), color = "blue")
}
time_source_tweet(2020)
time_source_tweet(2021)
retweet_date <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = retweet, y = tweet_date), color = "blue")
}
retweet_date(2020)
retweet_date(2021)
like_date <- function(year){
ggplot(data = blm_merged[blm_merged$year == year,]) +
geom_point(mapping = aes(x = like, y = tweet_date))
}
like_date(2020)
like_date(2021)
sentiment <- function(year){
tweets_sentiment <- iconv(tweets(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
sentiment <- function(year){
tweets_sentiment <- iconv(docs(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
sentiment <- function(year){
tweets_sentiment <- iconv(clouds(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
sentiment(2021)
tweets <- blm_merged[blm_merged$year == year,] %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- function(year){
tweets <- blm_merged[blm_merged$year == year,] %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball")
}
tweets <- function(year){
tweets <- blm_merged[blm_merged$year == year,] %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
}
sentiment <- function(year){
tweets_sentiment <- iconv(clouds(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
tweets <- function(year){
tweets <- blm_merged[blm_merged$year == year,] %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
}
sentiment <- function(year){
tweets_sentiment <- iconv(tweets(year), from="UTF-8", to="ASCII", sub="")# Converting tweets to ASCII to        trackle strange characters
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
# make plot
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores", year)+
theme_minimal()
}
sentiment(2020)
sentiment(2021)
#Retweet
RLR <- function(year){
for (i in year){
retweet <- (sum(blm_merged[blm_merged$year == year,]$retweet, na.rm = T))
like <- (sum(blm_merged[blm_merged$year == year,]$like, na.rm = T))
reply <- (sum(blm_merged[blm_merged$year == year,]$reply, na.rm = T))
quoted <- (sum(blm_merged[blm_merged$year == year,]$quote_count, na.rm = T))
}
RLRdata <- data.frame(category=c("Retweet", "Like", "Reply", "Quoted"), count = c(retweet, like, reply, quoted))
return(RLRdata)
}
RLRdata2020 <- RLR(2020)
RLRdata2020
RLRdata2021 <- RLR(2021)
#Adding columns
RLRdata2020$fraction = RLRdata2020$count / sum(RLRdata2020$count)
RLRdata2020$percentage = RLRdata2020$count / sum(RLRdata2020$count) * 100
RLRdata2020$ymax = cumsum(RLRdata2020$fraction)
RLRdata2020$ymin = c(0, head(RLRdata2020$ymax, n=-1))
#Rounding up
RLRdata2020 <- round_df(RLRdata2020, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(RLRdata2020$category, RLRdata2020$percentage, "%")
ggplot(RLRdata2020, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
#Adding columns
RLRdata2021$fraction = RLRdata2021$count / sum(RLRdata2021$count)
RLRdata2021$percentage = RLRdata2021$count / sum(RLRdata2021$count) * 100
RLRdata2021$ymax = cumsum(RLRdata2021$fraction)
RLRdata2021$ymin = c(0, head(RLRdata2021$ymax, n=-1))
#Rounding up
RLRdata2021 <- round_df(RLRdata2021, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(RLRdata2021$category, RLRdata2021$percentage, "%")
ggplot(RLRdata2021, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
library(stringr)
getCount <- function(blm_merged,year,keyword)
{
wcount <- str_count(blm_merged[blm_merged$year == year,]$text, keyword)
return(data.frame(data,wcount))
}
library(stringr)
getCount <- function(data,year,keyword)
{
wcount <- str_count(blm_merged[blm_merged$year == year,]$text, keyword)
return(data.frame(data,wcount))
}
getCount(blm_merged, 2021, 'pvv')
names <- c("pvv|vvd|CDA|D66|GroenLinks|SP|PVDA|ChristenUnie|pvdd|50plus|DENK|FVD|BIJ1")
library(stringr)
getCount <- function(data,year,keyword)
{
wcount <- str_count(blm_merged$text, keyword)
return(data.frame(data,wcount))
}
getCount(blm_merged, names)
getCount(blm_merged, "pvv|vvd|CDA|D66|GroenLinks|SP|PVDA|ChristenUnie|pvdd|50plus|DENK|FVD|BIJ1")
getCount(blm_merged, 'pvv')
library(stringr)
getCount <- function(data,keyword)
{
wcount <- str_count(blm_merged$text, keyword)
return(data.frame(data,wcount))
}
getCount(blm_merged, 'pvv')
getCount(blm_merged, names)
sum(wcount)
wcount <- getCount(blm_merged, names)
sum(wcount$wcount)
sum(wcount[wcount$year == 2020,]$wcount)
sum(wcount[wcount$year == 2020,]$wcount, na.rm = TRUE)
sum(wcount[wcount$year == 2021,]$wcount, na.rm = TRUE)
names <- c("pvv|vvd|CDA|D66|GroenLinks|SP|PVDA|ChristenUnie|pvdd|50plus|FVD|BIJ1")
#parties <- function(year){
#length(grep(names, blm_merged[blm_merged$year == 2020,]$text))}
#(2020)
library(stringr)
getCount <- function(data,keyword)
{
pvv <- str_count(blm_merged$text, keyword)
return(data.frame(data,wcount))
}
wcount <- getCount(blm_merged, names)
sum(wcount[wcount$year == 2021,]$wcount, na.rm = TRUE)
names <- c("pvv|vvd|CDA|D66|GroenLinks|SP|PVDA|ChristenUnie|pvdd|50plus|FVD|BIJ1")
#parties <- function(year){
#length(grep(names, blm_merged[blm_merged$year == 2020,]$text))}
#(2020)
library(stringr)
getCount <- function(data,keyword)
{
pvv <- str_count(blm_merged$text, keyword)
return(data.frame(data,wcount))
}
blm_merged$wcount <- getCount(blm_merged, names)
sum(wcount[wcount$year == 2021,]$wcount, na.rm = TRUE)
names <- c("pvv|vvd|CDA|D66|GroenLinks|SP|PVDA|ChristenUnie|pvdd|50plus|FVD|BIJ1")
#parties <- function(year){
#length(grep(names, blm_merged[blm_merged$year == 2020,]$text))}
#(2020)
library(stringr)
getCount <- function(data,keyword)
{
pvv <- str_count(blm_merged$text, keyword)
return(data.frame(data,wcount))
}
wcount_df <- getCount(blm_merged, names)
sum(wcount[wcount$year == 2021,]$wcount, na.rm = TRUE)
ggplot(data = wcount) +
geom_point(mapping = aes(x = wcount, y = tweet_date), color = "blue")
ggplot(data = wcount) +
geom_point(mapping = aes(x = wcount, y = tweet_date), color = "yellow")
ggplot(data = wcount) +
geom_point(mapping = aes(x = wcount, y = tweet_date), color = "yellow")
