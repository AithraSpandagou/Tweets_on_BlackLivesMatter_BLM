})
# Loop through all of the data
dir.create('../../gen/data-preparation/temp', recursive= TRUE)
prepared_data <- list()
for (i in seq(along=data_blm)) {
print(i)
blmdata = data_blm[[i]]
fn = filenames[i]
extracted_filename = rev(strsplit(fn, '/')[[1]])[1]
# Get a first look of the data
blmdata$retweeted_tweet[is.na(blmdata$retweeted_tweet)] <- 0
blmdata$quoted_tweet[is.na(blmdata$quoted_tweet)] <- "No"
# Remove duplicates with the distinct function
sum(duplicated(blmdata))
blmdata %>% distinct(blmdata$tweet_id)
# See the type of data of the variables
glimpse(blmdata)
# Separate the date and the time into 2 variables
blmdata$date <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 1)
blmdata$time <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 2)
#see the class of the date
class(blmdata$date)
# The data is a character and needs to be converted into a date variable
blmdata$date <- as.Date(blmdata$date, format = c("%Y-%m-%d"))
# Make the Time variable readable
blmdata$time <- gsub(x=blmdata$time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blmdata = subset(blmdata, select = -c(datetime))
# remove weird characters (rendered) content tweet and user description
blmdata$text <- gsub(x=blmdata$text, pattern="\r\n",replacement="", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã¢Ëâ¦ ", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã°Å¸", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã°Å¸Â¤", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Â©", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "HÃÂ©", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ëâ°", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Â¤âËâÂ¤Â£âÅ ", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã¢â¬â¢", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern="\r\n",replacement="", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern= "Ã¢Ëâ¦ ", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Ã°Å¸", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Â¤", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "HÃÂ©", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Ã", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Â©", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern="\r\n",replacement="", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
blmdata$user_description<- gsub(x=blmdata$user_description, pattern= "Ã¢Ëâ¦ ", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã°Å¸", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã°Å¸Â¤", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Â©", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "â¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Å", replacement = "", fixed = T)
# clean source attribute to useful
html_tags <- c(
"<bold>Random</bold> text with symbols: &nbsp; &lt; &gt; &amp; &quot; &apos;",
"<p>More text</p> &cent; &pound; &yen; &euro; &copy; &reg;"
)
blmdata$source_tweet<- replace_html(blmdata$source_tweet)
prepared_data[[i]] <- blmdata
write.table(blmdata, paste0('../../gen/data-preparation/temp/', extracted_filename))
}
BLM_merged<- rbind(blm_data)
write.csv(BLM_merged, '../../gen/data-preparation/merging.csv')
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'], sep = '\t', na.string = c(" ", "NA"))
write.csv(blm_data, paste0('../../datasets/', i['target']), quote = TRUE, fileEncoding = "")
}
library(dplyr)
library(tidyr)
library(textclean)
# install.packages(pandas)
# library(pandas)
# download data
filenames = c('../../datasets/BLM2020_dataset.csv',
'../../datasets/BLM2021_dataset.csv')
data_blm = lapply(filenames,
function(fn) {
read.csv(
fn, sep = ',' , na.string = c(" ", "NA")
)
})
# Loop through all of the data
dir.create('../../gen/data-preparation/temp', recursive= TRUE)
prepared_data <- list()
for (i in seq(along=data_blm)) {
print(i)
blmdata = data_blm[[i]]
fn = filenames[i]
extracted_filename = rev(strsplit(fn, '/')[[1]])[1]
# Get a first look of the data
blmdata$retweeted_tweet[is.na(blmdata$retweeted_tweet)] <- 0
blmdata$quoted_tweet[is.na(blmdata$quoted_tweet)] <- "No"
# Remove duplicates with the distinct function
sum(duplicated(blmdata))
blmdata %>% distinct(blmdata$tweet_id)
# See the type of data of the variables
glimpse(blmdata)
# Separate the date and the time into 2 variables
blmdata$date <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 1)
blmdata$time <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 2)
#see the class of the date
class(blmdata$date)
# The data is a character and needs to be converted into a date variable
blmdata$date <- as.Date(blmdata$date, format = c("%Y-%m-%d"))
# Make the Time variable readable
blmdata$time <- gsub(x=blmdata$time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blmdata = subset(blmdata, select = -c(datetime))
# remove weird characters (rendered) content tweet and user description
blmdata$text <- gsub(x=blmdata$text, pattern= "\r\n",replacement="", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã¢Ëâ¦ ", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã°Å¸", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã°Å¸Â¤", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Â©", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "HÃÂ©", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ëâ°", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Â¤âËâÂ¤Â£âÅ", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã¢â¬â¢", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern="\r\n",replacement="", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern= "Ã¢Ëâ¦ ", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Ã°Å¸", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Â¤", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "HÃÂ©", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Ã", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Â©", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern="\r\n",replacement="", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
blmdata$user_description<- gsub(x=blmdata$user_description, pattern= "Ã¢Ëâ¦ ", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã°Å¸", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã°Å¸Â¤", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Â©", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "â¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Å", replacement = "", fixed = T)
# clean source attribute to useful
html_tags <- c(
"<bold>Random</bold> text with symbols: &nbsp; &lt; &gt; &amp; &quot; &apos;",
"<p>More text</p> &cent; &pound; &yen; &euro; &copy; &reg;"
)
blmdata$source_tweet<- replace_html(blmdata$source_tweet)
prepared_data[[i]] <- blmdata
write.table(blmdata, paste0('../../gen/data-preparation/temp/', extracted_filename))
}
BLM_merged<- rbind(blm_data)
write.csv(BLM_merged, '../../gen/data-preparation/merging.csv')
View(BLM_merged)
View(BLM_merged)
BLM_merged<- rbind(blm_data)
dir.create('../../gen/data-preparation/merged_data', recursive= TRUE)
write.csv(BLM_merged, '../../gen/data-preparation/merged_data/merging.csv')
dir.create('../../datasets', recursive= TRUE)
files = list(
c(url = 'https://www.dropbox.com/s/7ywlwmynitdb2rr/BLM2020_Dataset.csv?dl=1', target =
'BLM2020_dataset.csv'),
c(url = 'https://www.dropbox.com/s/glpv88v6hb0u4j1/BLM2021_Dataset.csv?dl=1', target =
'BLM2021_dataset.csv'))
library(data.table)
for (i in files) {
print(i)
#i['url']
#i['target']
blm_data <- read.csv(i['url'], sep = '\t', na.string = c(" ", "NA"))
write.csv(blm_data, paste0('../../datasets/', i['target']), quote = TRUE, fileEncoding = "")
}
library(data.table)
library(dplyr)
library(tidyr)
library(textclean)
# install.packages(pandas)
# library(pandas)
# download data
filenames = c('../../datasets/BLM2020_dataset.csv',
'../../datasets/BLM2021_dataset.csv')
data_blm = lapply(filenames,
function(fn) {
read.csv(
fn, sep = ',' , na.string = c(" ", "NA")
)
})
# Loop through all of the data
dir.create('../../gen/data-preparation/temp', recursive= TRUE)
prepared_data <- list()
for (i in seq(along=data_blm)) {
print(i)
blmdata = data_blm[[i]]
fn = filenames[i]
extracted_filename = rev(strsplit(fn, '/')[[1]])[1]
# Get a first look of the data
blmdata$retweeted_tweet[is.na(blmdata$retweeted_tweet)] <- 0
blmdata$quoted_tweet[is.na(blmdata$quoted_tweet)] <- "No"
# Remove duplicates with the distinct function
sum(duplicated(blmdata))
blmdata %>% distinct(blmdata$tweet_id)
# See the type of data of the variables
glimpse(blmdata)
# Separate the date and the time into 2 variables
blmdata$date <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 1)
blmdata$time <- sapply(strsplit(as.character(blmdata$datetime), " "), "[", 2)
#see the class of the date
class(blmdata$date)
# The data is a character and needs to be converted into a date variable
blmdata$date <- as.Date(blmdata$date, format = c("%Y-%m-%d"))
# Make the Time variable readable
blmdata$time <- gsub(x=blmdata$time, pattern="+00:00",replacement="",fixed=T)
# Remove the Datetime variable and create a new dataframe
blmdata = subset(blmdata, select = -c(datetime))
# remove weird characters (rendered) content tweet and user description
blmdata$text <- gsub(x=blmdata$text, pattern= "\r\n",replacement="", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã¢Ëâ¦ ", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã°Å¸", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã°Å¸Â¤", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Â©", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "HÃÂ©", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ëâ°", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Â¤âËâÂ¤Â£âÅ", replacement = "", fixed = T)
blmdata$text <- gsub(x=blmdata$text, pattern = "Ã¢â¬â¢", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern="\r\n",replacement="", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_content, pattern= "Ã¢Ëâ¦ ", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Ã°Å¸", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Â¤", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "HÃÂ©", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Ã", replacement = "", fixed = T)
#blmdata$rendered_content <- gsub(x=blmdata$rendered_Content, pattern= "Â©", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern="\r\n",replacement="", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern="Ã¢â¬Â¢",replacement="", fixed = T)
blmdata$user_description<- gsub(x=blmdata$user_description, pattern= "Ã¢Ëâ¦ ", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã°Å¸", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã°Å¸Â¤", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Â©", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Ã¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "â¢", replacement = "", fixed = T)
blmdata$user_description <- gsub(x=blmdata$user_description, pattern= "Å", replacement = "", fixed = T)
# clean source attribute to useful
html_tags <- c(
"<bold>Random</bold> text with symbols: &nbsp; &lt; &gt; &amp; &quot; &apos;",
"<p>More text</p> &cent; &pound; &yen; &euro; &copy; &reg;"
)
blmdata$source_tweet<- replace_html(blmdata$source_tweet)
prepared_data[[i]] <- blmdata
write.table(blmdata, paste0('../../gen/data-preparation/temp/', extracted_filename))
}
BLM_merged<- rbind(blm_data)
dir.create('../../gen/data-preparation/merged_data', recursive= TRUE)
write.csv(BLM_merged, '../../gen/data-preparation/merged_data/merging.csv')
library(rtweet)
library(rtweet)
install.packages(rtweet)
library(rtweet)
install.packages(rtweet)
install.packages(rtweet)
install.package(rtweet)
library(dplyr)
library(tidyr)
library(tidytext)
install.packages("tidytext")
install.packages("rtweet")
install.packages("rtweet")
library(ggplot.multistats)
library(ggplot.multistats)
install.packages("ggplot.multistats")
library(ggplot.multistats)
library(ggplot.multistats)
library(ggplot2)
library(forestmangr)
install.packages("forestmangr")
install.packages("forestmangr")
library(forestmangr)
install.packages("syuzhet")
library(syuzhet)
library(tidyverse)
library(tidyverse)
library(readxl) # read excel
library(tibble) # tobble dataframe
library(dplyr) # piping
library(stringr) # character manipulation
library(tidytext)
library(tokenizers)
library(stopwords)
install.packages("stopwords")
library(stopwords)
library(lobstr)
install.packages("lobstr")
library(glue)
library(lobstr)
library(stringr)
library(glue)
blm2020<-read.csv('../../gen/data-preparation/temp/BLM2020_dataset.csv', sep = ' ', na.strings=c("", "NA"))
blm2021<-read.csv('../../gen/data-preparation/temp/BLM2021_dataset.csv', sep = '', na.strings=c("", "NA"))
blm2020_retweets<-blm2020[blm2020$retweet > 1, ]
blm2020_retweets
blm2021_retweets<-blm2021[blm2021$retweet > 1, ]
blm2021_retweets
blm2020_likes<-blm2020[blm2020$like >1, ]
blm2020_likes
blm2021_likes<-blm2021[blm2021$like >1, ]
blm2021_likes
blm2020_replies<-blm2020[blm2020$reply >1, ]
blm2020_replies
count(blm2020_replies)
blm2021_replies<-blm2021[blm2021$reply >1, ]
blm2021_replies
count(blm2021_replies)
data2020<-data.frame(category=c("Retweets", "Likes", "Replies"), count=c(2, 5, 3))
data2020
data2021<-data.frame(category=c("Retweets", "Likes", "Replies"), count=c(707, 1738, 574))
data2021
data2020$fraction = data2020$count / sum(data2020$count)
data2020$percentage = data2020$count / sum(data2020$count) * 100
data2020$ymax = cumsum(data2020$fraction)
data2020$ymin = c(0, head(data2020$ymax, n=-1))
data2020 <- round_df(data2020, 2)
Type_of_Tweet <- paste(data2020$category, data2020$percentage, "%")
ggplot(data2020, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
#Adding columns
data2021$fraction = data2021$count / sum(data2021$count)
data2021$percentage = data2021$count / sum(data2021$count) * 100
data2021$ymax = cumsum(data2021$fraction)
data2021$ymin = c(0, head(data2021$ymax, n=-1))
#Rounding up
data2021 <- round_df(data2021, 2)
# Specify what the legend should say
Type_of_Tweet <- paste(data2020$category, data2021$percentage, "%")
ggplot(data2021, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Type_of_Tweet)) +
geom_rect() +
coord_polar(theta="y") +
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
blm2020$text <- gsub("@\\S*", "", blm2020$text)
blm2020$text <- gsub("amp", "", blm2020$text)
blm2020$text <- gsub("[\r\n]", "", blm2020$text)
blm2020$text <- gsub("[[:punct:]]", "", blm2020$text)
#removing stop words from the text - so the most frequent words are not or at and
tweets <- blm2020 %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
#making a histogram
tweets %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM",
subtitle = "Stop words removed from the list")
blm2021$text <- gsub("@\\S*", "", blm2021$text)
blm2021$text <- gsub("amp", "", blm2021$text)
blm2021$text <- gsub("[\r\n]", "", blm2021$text)
blm2021$text <- gsub("[[:punct:]]", "", blm2021$text)
#removing stop words from the text - so the most frequent words are not or at and
tweets1 <- blm2021 %>%
select(text) %>%
unnest_tokens(word, text)
tweets1 <- tweets1 %>%
anti_join(get_stopwords(language = "nl", source = "snowball"))
#making a histogram
tweets1 %>% # gives you a bar chart of the most frequent words found in the tweets
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets of #BLM 2021",
subtitle = "Stop words removed from the list")
# Converting tweets to ASCII to trackle strange characters
tweets_sentiment <- iconv(tweets, from="UTF-8", to="ASCII", sub="")
# removing retweets, in case needed
tweets_sentiment <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment)
# removing mentions, in case needed
tweets_sentiment <-gsub("@\\w+","",tweets_sentiment)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores 2020")+
theme_minimal()
# Converting tweets to ASCII to trackle strange characters
tweets_sentiment_1 <- iconv(tweets, from="UTF-8", to="ASCII", sub="")
# removing retweets, in case needed
tweets_sentiment_1 <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets_sentiment_1)
# removing mentions, in case needed
tweets_sentiment_1 <-gsub("@\\w+","",tweets_sentiment_1)
ew_sentiment<-get_nrc_sentiment((tweets_sentiment))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores 2021")+
theme_minimal()
#Making a ggplot
#ploting retweets by location
ggplot(data = blm2020) +
geom_point(mapping = aes(x = retweet, y = location))
#ploting retweets by datetime
#need to separate date from time
ggplot(data = blm2020) +
geom_point(mapping = aes(x = retweet, y = datetime), color = "blue")
#ploting retweets by datetime
#need to separate date from time
ggplot(data = blm2020) +
geom_point(mapping = aes(x = retweet, y = blm2020$datetime), color = "blue")
ggplot(data = blm2020) +
geom_point(mapping = aes(x = user_amount_followers, y = user_amount_friends), color = "blue")
ggplot(data = blm2020) +
geom_point(mapping = aes(x = user_amount_status, y = location), color = "blue")
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", state.name)]
#Making a ggplot
#ploting retweets by location
ggplot(data = blm2021) +
geom_point(mapping = aes(x = retweet, y = location))
#ploting retweets by datetime
#need to separate date from time
ggplot(data = blm2021) +
geom_point(mapping = aes(x = retweet, y = datetime), color = "blue")
ggplot(data = blm2021) +
geom_point(mapping = aes(x = user_amount_followers, y = user_amount_friends), color = "blue")
#remove dollar signs
blm2020<-gsub("\\$", "", blm2020)
blm2021<-gsub("\\$","", blm2021)
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", state.name)]
# create a list of tokens
#https://www.kaggle.com/rtatman/tokenization-tutorial
tokens_2020<-data.frame(text= blm2020) %>% unnest_tokens(word, text)
tokens_2020
tokens_2021<-data.frame(text=blm2021) %>% unnest_tokens(word, text)
tokens_2021
# get the sentiment from the first text:
tokens_2020 %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
#do the same for 2021
tokens_2021 %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
blm2020$sentiment<-get_sentiment(blm2020$text)
#2020
one.way_2020 <- aov(sentiment ~ source_tweet , data = blm2020)
#2021
one.way_2021 <- aov(sentiment ~ source_tweet, data = blm2021)
View(data2020)
View(data2020)
View(BLM_merged)
View(BLM_merged)
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", "D66", "BIJ1", state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", "D66", state.name)]
state.name[grep ("VVD", "PvdA", "PVV", "CDA", "SP", "CU", "PvdD", state.name)]
blm2020 %>%
group_by(group) %>%
get_summary_stats(blm2020$user_amount_followers, type = "mean_sd")
library(tidyverse)
library(ggpubr)
library(rstatix)
library(rstatix)
blm2020 %>%
group_by(group) %>%
get_summary_stats(blm2020$user_amount_followers, type = "mean_sd")
blm2020 %>%
group_by(blm2020$user_amount_followers) %>%
get_summary_stats(blm2020$user_amount_followers, type = "mean_sd")
one.way <- aov(blmdata ~ qoute_count, data = crop.data)
